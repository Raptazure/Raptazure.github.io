{"componentChunkName":"component---src-templates-post-tsx","path":"/posts/mit-6.824/","result":{"data":{"site":{"siteMetadata":{"title":"Raptazure","description":"朝の祈り","author":{"name":"raptazure","twitter":"https://twitter.com/raptazure","github":"https://github.com/raptazure"}}},"mdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"6.824 Distributed Systems\",\n  \"date\": \"2020-08-22T00:00:00.000Z\",\n  \"tags\": [\"computer science\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"1. Introduction\"), mdx(\"h3\", null, \"Why distributed systems?\"), mdx(\"p\", null, \"Parallelism, fault tolerance, physical reasons, security / isolated\"), mdx(\"h3\", null, \"Basic challenges\"), mdx(\"p\", null, \"Concurrency, partial failure, performance\"), mdx(\"h3\", null, \"Fault tolerance tools\"), mdx(\"p\", null, \"Non-volatile storage (expensive)\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"Replication (make replicas have independent failure probability)\"), mdx(\"h3\", null, \"Consistency\"), mdx(\"p\", null, \"Strong consistency is expensive to implement.\", mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", \"To avoid communication as much as possible particularly if replicas are far away, pepole build weak systems that might allow the stale read of an old value.\"), mdx(\"h3\", null, \"MapReduce\"), mdx(\"p\", null, \"The MapReduce algorithm contains two important tasks, namely Map and Reduce. Map takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs). Secondly, reduce task, which takes the output from a map as an input and combines those data tuples into a smaller set of tuples. As the sequence of the name MapReduce implies, the reduce task is always performed after the map job. The entire job is made up of a bunch of map tasks and a bunch of reduce tasks. Example: word count.\"), mdx(\"h1\", null, \"2. RPC and Threads\"), mdx(\"h3\", null, \"Threads\"), mdx(\"p\", null, \"Threads allow one program to do many things at once. each thread executes serially, just like an ordinary non-threaded program. the threads share memory. each thread includes some per-thread state: program counter, registers, stack.\"), mdx(\"p\", null, \"Why threads?\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"They express concurrency, which you need in distributed systems\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"I/O concurrency\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Client sends requests to many servers in parallel and waits for replies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Server processes multiple client requests; each request may block.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"While waiting for the disk to read data for client X, process a request from client Y.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Multicore performance\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Execute code in parallel on several cores.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"In background, once per second, check whether each worker is still alive.\")), mdx(\"p\", null, \"Is there an alternative to threads?\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Write code that explicitly interleaves activities, in a single thread.\\nUsually called \\u201Cevent-driven.\\u201D\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Keep a table of state about each activity, e.g. each client request.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"One \\u201Cevent\\u201D loop that: checks for new input for each activity (e.g. arrival of reply from server), does the next step for each activity, updates state.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Event-driven gets you I/O concurrency, and eliminates thread costs (which can be substantial), but doesn\\u2019t get multi-core speedup.\")), mdx(\"p\", null, \"Threading challenges:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Shared data. e.g. what if two threads do n = n + 1 at the same time? or one thread reads while another increments? this is a \\u201Crace\\u201D - and is usually a bug. -> use locks or avoid sharing mutable data.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Coordination between threads.\\ne.g. one thread is producing data, another thread is consuming it.\\nhow can the consumer wait (and release the CPU)?\\nhow can the producer wake up the consumer?\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Deadlock: cycles via locks and/or communication (e.g. RPC or channels)\")), mdx(\"h3\", null, \"Remote Procedure Call\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RPC is a powerful technique for constructing distributed, client-server based applications. It is based on extending the conventional local procedure calling so that the called procedure need not exist in the same address space as the calling procedure. The two processes may be on the same system, or they may be on different systems with a network connecting them.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Goal: easy-to-program client/server communication, hide details of network protocols, convert data (strings, arrays, maps, &c) to wire format.\")));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"1. Introduction Why distributed systems? Parallelism, fault tolerance, physical reasons, security / isolated Basic challenges Concurrency…","fields":{"lang":"zh-Hans"},"frontmatter":{"title":"6.824 Distributed Systems","date":"2020-08-22","tags":["computer science"]}}},"pageContext":{"slug":"/posts/mit-6.824/"}},"staticQueryHashes":["2345487092"]}